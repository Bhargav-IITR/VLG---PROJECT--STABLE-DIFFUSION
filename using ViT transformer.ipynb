{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install rouge_score -q\n!pip install deep-phonemizer -q\nclear_output()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:12:33.575375Z","iopub.execute_input":"2023-06-22T17:12:33.575764Z","iopub.status.idle":"2023-06-22T17:12:57.024005Z","shell.execute_reply.started":"2023-06-22T17:12:33.575730Z","shell.execute_reply":"2023-06-22T17:12:57.022818Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"! pip install -U git+https://github.com/huggingface/transformers.git\n! pip install -U git+https://github.com/huggingface/accelerate.git","metadata":{"execution":{"iopub.status.busy":"2023-06-22T17:12:57.026360Z","iopub.execute_input":"2023-06-22T17:12:57.027130Z","iopub.status.idle":"2023-06-22T17:13:59.430191Z","shell.execute_reply.started":"2023-06-22T17:12:57.027084Z","shell.execute_reply":"2023-06-22T17:13:59.428918Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-8_q_bk2_\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-8_q_bk2_\n  Resolved https://github.com/huggingface/transformers.git to commit a1c4b63076ed11946a24a3d2e3ab7d7e77819546\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (21.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (4.13.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (0.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (2.28.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (1.21.6)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (4.64.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (0.12.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (0.15.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (2021.11.10)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.31.0.dev0) (3.7.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0) (4.1.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0) (2022.8.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.31.0.dev0) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.31.0.dev0) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.31.0.dev0) (2023.5.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.31.0.dev0) (1.26.12)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.31.0.dev0) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.31.0.dev0) (3.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting git+https://github.com/huggingface/accelerate.git\n  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-zs3ic03c\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-zs3ic03c\n  Resolved https://github.com/huggingface/accelerate.git to commit b16916f44795bd960bc734992d2819a955064935\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate==0.21.0.dev0) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.21.0.dev0) (21.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.21.0.dev0) (1.21.6)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate==0.21.0.dev0) (5.9.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from accelerate==0.21.0.dev0) (1.11.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->accelerate==0.21.0.dev0) (3.0.9)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (4.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nimport datasets\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport multiprocessing as mp\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import io, transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\n\nfrom transformers import Seq2SeqTrainer ,Seq2SeqTrainingArguments\nfrom transformers import VisionEncoderDecoderModel , ViTFeatureExtractor\nfrom transformers import AutoTokenizer ,  GPT2Config , default_data_collator\n\n\nif torch.cuda.is_available():    \n\n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:13:59.432622Z","iopub.execute_input":"2023-06-22T17:13:59.433436Z","iopub.status.idle":"2023-06-22T17:13:59.444977Z","shell.execute_reply.started":"2023-06-22T17:13:59.433387Z","shell.execute_reply":"2023-06-22T17:13:59.443918Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"\nclass config : \n    ENCODER = \"google/vit-base-patch16-224\"\n    DECODER = \"gpt2\"\n    TRAIN_BATCH_SIZE = 8\n    VAL_BATCH_SIZE = 8\n    VAL_EPOCHS = 1\n    LR = 5e-5\n    SEED = 42\n    MAX_LEN = 128\n    SUMMARY_LEN = 20\n    WEIGHT_DECAY = 0.01\n    MEAN = (0.485, 0.456, 0.406)\n    STD = (0.229, 0.224, 0.225)\n    TRAIN_PCT = 0.95\n    NUM_WORKERS = mp.cpu_count()\n    EPOCHS = 3\n    IMG_SIZE = (224,224)\n    LABEL_MASK = -100\n    TOP_K = 1000\n    TOP_P = 0.95","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-06-22T17:13:59.447835Z","iopub.execute_input":"2023-06-22T17:13:59.449064Z","iopub.status.idle":"2023-06-22T17:13:59.462312Z","shell.execute_reply.started":"2023-06-22T17:13:59.449024Z","shell.execute_reply":"2023-06-22T17:13:59.461339Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n    outputs = [self.bos_token_id] + token_ids_0 + [self.eos_token_id]\n    return outputs\nAutoTokenizer.build_inputs_with_special_tokens = build_inputs_with_special_tokens","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:13:59.463943Z","iopub.execute_input":"2023-06-22T17:13:59.464379Z","iopub.status.idle":"2023-06-22T17:13:59.474320Z","shell.execute_reply.started":"2023-06-22T17:13:59.464341Z","shell.execute_reply":"2023-06-22T17:13:59.473293Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"rouge = datasets.load_metric(\"rouge\")\n\ndef compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    # all unnecessary tokens are removed\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n\n    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n\n    return {\n        \"rouge2_precision\": round(rouge_output.precision, 4),\n        \"rouge2_recall\": round(rouge_output.recall, 4),\n        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n    }\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-22T17:13:59.477807Z","iopub.execute_input":"2023-06-22T17:13:59.478239Z","iopub.status.idle":"2023-06-22T17:14:00.342824Z","shell.execute_reply.started":"2023-06-22T17:13:59.478199Z","shell.execute_reply":"2023-06-22T17:14:00.341782Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"feature_extractor = ViTFeatureExtractor.from_pretrained(config.ENCODER)\ntokenizer = AutoTokenizer.from_pretrained(config.DECODER)\ntokenizer.pad_token = tokenizer.unk_token","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:00.344224Z","iopub.execute_input":"2023-06-22T17:14:00.344935Z","iopub.status.idle":"2023-06-22T17:14:01.392381Z","shell.execute_reply.started":"2023-06-22T17:14:00.344896Z","shell.execute_reply":"2023-06-22T17:14:01.391329Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/models/vit/feature_extraction_vit.py:31: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"transforms = transforms.Compose(\n    [\n        transforms.Resize(config.IMG_SIZE), \n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=0.5, \n            std=0.5\n        )\n   ]\n)\ndf=  pd.read_csv(\"/kaggle/input/flickr8k/captions.txt\")\ntrain_df , val_df = train_test_split(df , test_size = 0.2)\ndf.head()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:01.394109Z","iopub.execute_input":"2023-06-22T17:14:01.394550Z","iopub.status.idle":"2023-06-22T17:14:01.464975Z","shell.execute_reply.started":"2023-06-22T17:14:01.394508Z","shell.execute_reply":"2023-06-22T17:14:01.463818Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                       image  \\\n0  1000268201_693b08cb0e.jpg   \n1  1000268201_693b08cb0e.jpg   \n2  1000268201_693b08cb0e.jpg   \n3  1000268201_693b08cb0e.jpg   \n4  1000268201_693b08cb0e.jpg   \n\n                                             caption  \n0  A child in a pink dress is climbing up a set o...  \n1              A girl going into a wooden building .  \n2   A little girl climbing into a wooden playhouse .  \n3  A little girl climbing the stairs to her playh...  \n4  A little girl in a pink dress going into a woo...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A child in a pink dress is climbing up a set o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A girl going into a wooden building .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing into a wooden playhouse .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing the stairs to her playh...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl in a pink dress going into a woo...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class ImgDataset(Dataset):\n    def __init__(self, df,root_dir,tokenizer,feature_extractor, transform = None):\n        self.df = df\n        self.transform = transform\n        self.root_dir = root_dir\n        self.tokenizer= tokenizer\n        self.feature_extractor = feature_extractor\n        self.max_length = 50\n    def __len__(self,):\n        return len(self.df)\n    def __getitem__(self,idx):\n        caption = self.df.caption.iloc[idx]\n        image = self.df.image.iloc[idx]\n        img_path = os.path.join(self.root_dir , image)\n        img = Image.open(img_path).convert(\"RGB\")\n        \n        if self.transform is not None:\n            img= self.transform(img)\n        pixel_values = self.feature_extractor(img, return_tensors=\"pt\").pixel_values\n        captions = self.tokenizer(caption,\n                                 padding='max_length',\n                                 max_length=self.max_length).input_ids\n        captions = [caption if caption != self.tokenizer.pad_token_id else -100 for caption in captions]\n        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(captions)}\n        return encoding\n        \n        ","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-06-22T17:14:01.466691Z","iopub.execute_input":"2023-06-22T17:14:01.467098Z","iopub.status.idle":"2023-06-22T17:14:01.478485Z","shell.execute_reply.started":"2023-06-22T17:14:01.467059Z","shell.execute_reply":"2023-06-22T17:14:01.477361Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"train_dataset = ImgDataset(train_df, root_dir = \"/kaggle/input/flickr8k/Images\",tokenizer=tokenizer,feature_extractor = feature_extractor ,transform = transforms)\nval_dataset = ImgDataset(val_df , root_dir = \"/kaggle/input/flickr8k/Images\",tokenizer=tokenizer,feature_extractor = feature_extractor , transform  = transforms)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:01.483579Z","iopub.execute_input":"2023-06-22T17:14:01.483956Z","iopub.status.idle":"2023-06-22T17:14:01.492428Z","shell.execute_reply.started":"2023-06-22T17:14:01.483913Z","shell.execute_reply":"2023-06-22T17:14:01.491277Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(config.ENCODER, config.DECODER)","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:01.493820Z","iopub.execute_input":"2023-06-22T17:14:01.494446Z","iopub.status.idle":"2023-06-22T17:14:05.762680Z","shell.execute_reply.started":"2023-06-22T17:14:01.494406Z","shell.execute_reply":"2023-06-22T17:14:05.760825Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.0.ln_cross_attn.weight', 'h.5.crossattention.c_proj.weight', 'h.7.ln_cross_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.6.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.weight', 'h.5.ln_cross_attn.bias', 'h.7.crossattention.c_proj.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_attn.bias', 'h.8.crossattention.c_proj.weight', 'h.10.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.bias', 'h.6.crossattention.c_proj.weight', 'h.6.ln_cross_attn.weight', 'h.9.crossattention.q_attn.bias', 'h.0.ln_cross_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.10.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.5.ln_cross_attn.weight', 'h.1.crossattention.q_attn.bias', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.q_attn.weight', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.q_attn.weight', 'h.3.crossattention.c_attn.weight', 'h.1.ln_cross_attn.weight', 'h.3.crossattention.q_attn.bias', 'h.11.ln_cross_attn.bias', 'h.8.ln_cross_attn.bias', 'h.10.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.bias', 'h.7.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.bias', 'h.9.ln_cross_attn.weight', 'h.1.crossattention.q_attn.weight', 'h.7.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.5.crossattention.q_attn.bias', 'h.6.ln_cross_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.9.crossattention.c_proj.weight', 'h.1.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.6.crossattention.c_attn.bias', 'h.1.crossattention.c_proj.bias', 'h.10.crossattention.c_attn.weight', 'h.7.crossattention.q_attn.bias', 'h.3.crossattention.c_proj.bias', 'h.11.crossattention.q_attn.weight', 'h.1.crossattention.c_proj.weight', 'h.4.crossattention.c_attn.bias', 'h.8.crossattention.c_proj.bias', 'h.3.ln_cross_attn.weight', 'h.2.crossattention.c_attn.weight', 'h.1.crossattention.c_attn.weight', 'h.11.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.4.crossattention.c_proj.bias', 'h.4.ln_cross_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.7.crossattention.c_attn.weight', 'h.9.ln_cross_attn.bias', 'h.5.crossattention.c_proj.bias', 'h.0.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.4.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.crossattention.q_attn.bias', 'h.11.crossattention.c_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.11.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.8.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.0.crossattention.c_proj.weight', 'h.7.crossattention.c_proj.bias', 'h.10.ln_cross_attn.weight', 'h.2.crossattention.c_proj.weight', 'h.8.crossattention.c_attn.weight', 'h.7.crossattention.q_attn.weight', 'h.0.crossattention.c_attn.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.decoder_start_token_id = tokenizer.cls_token_id\nmodel.config.pad_token_id = tokenizer.pad_token_id\n# make sure vocab size is set correctly\nmodel.config.vocab_size = model.config.decoder.vocab_size\n# set beam search parameters\nmodel.config.eos_token_id = tokenizer.sep_token_id\nmodel.config.decoder_start_token_id = tokenizer.bos_token_id\nmodel.config.max_length = 128\nmodel.config.early_stopping = True\nmodel.config.no_repeat_ngram_size = 3\nmodel.config.length_penalty = 2.0\nmodel.config.num_beams = 4","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:05.765820Z","iopub.execute_input":"2023-06-22T17:14:05.766568Z","iopub.status.idle":"2023-06-22T17:14:05.780565Z","shell.execute_reply.started":"2023-06-22T17:14:05.766488Z","shell.execute_reply":"2023-06-22T17:14:05.778429Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='VIT_large_gpt2',\n    per_device_train_batch_size=config.TRAIN_BATCH_SIZE,\n    per_device_eval_batch_size=config.VAL_BATCH_SIZE,\n    predict_with_generate=True,\n    evaluation_strategy=\"epoch\",\n    do_train=True,\n    do_eval=True,\n    logging_steps=1024,  \n    save_steps=2048, \n    warmup_steps=1024,  \n    learning_rate = 5e-5,\n    #max_steps=1500, # delete for full training\n    num_train_epochs = config.EPOCHS, #TRAIN_EPOCHS\n    overwrite_output_dir=True,\n    save_total_limit=1,\n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:05.786256Z","iopub.execute_input":"2023-06-22T17:14:05.786825Z","iopub.status.idle":"2023-06-22T17:14:05.814217Z","shell.execute_reply.started":"2023-06-22T17:14:05.786787Z","shell.execute_reply":"2023-06-22T17:14:05.813082Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    tokenizer=feature_extractor,\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=default_data_collator,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T17:14:05.818818Z","iopub.execute_input":"2023-06-22T17:14:05.819165Z","iopub.status.idle":"2023-06-22T17:14:07.756115Z","shell.execute_reply.started":"2023-06-22T17:14:05.819129Z","shell.execute_reply":"2023-06-22T17:14:07.754830Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:415: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_289/\u001b[0m\u001b[1;33m2896216190.py\u001b[0m:\u001b[94m11\u001b[0m in \u001b[92m<module>\u001b[0m                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_289/2896216190.py'\u001b[0m                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1543\u001b[0m in \u001b[92mtrain\u001b[0m                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1540 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1541 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1542 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1543 \u001b[2m│   │   │   \u001b[0mignore_keys_for_eval=ignore_keys_for_eval,                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1544 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1545 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1546 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_inner_training_loop\u001b[0m(                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1779\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1776 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mrng_to_sync = \u001b[94mTrue\u001b[0m                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1777 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1778 \u001b[0m\u001b[2m│   │   │   \u001b[0mstep = -\u001b[94m1\u001b[0m                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1779 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m step, inputs \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(epoch_iterator):                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1780 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtotal_batched_samples += \u001b[94m1\u001b[0m                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1781 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m rng_to_sync:                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1782 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._load_rng_state(resume_from_checkpoint)                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/accelerate/\u001b[0m\u001b[1;33mdata_loader.py\u001b[0m:\u001b[94m377\u001b[0m in \u001b[92m__iter__\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m374 \u001b[0m\u001b[2m│   │   \u001b[0mdataloader_iter = \u001b[96msuper\u001b[0m().\u001b[92m__iter__\u001b[0m()                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m375 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# We iterate one batch ahead to check when we are at the end\u001b[0m                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m376 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m377 \u001b[2m│   │   │   \u001b[0mcurrent_batch = \u001b[96mnext\u001b[0m(dataloader_iter)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m378 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mStopIteration\u001b[0m:                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m379 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94myield\u001b[0m                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m380 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m530\u001b[0m in \u001b[92m__next__\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 527 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.autograd.profiler.record_function(\u001b[96mself\u001b[0m._profile_name):                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 528 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._reset()                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 530 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 531 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 532 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m:\u001b[94m570\u001b[0m in \u001b[92m_next_data\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 567 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 568 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_next_data\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 569 \u001b[0m\u001b[2m│   │   \u001b[0mindex = \u001b[96mself\u001b[0m._next_index()  \u001b[2m# may raise StopIteration\u001b[0m                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 570 \u001b[2m│   │   \u001b[0mdata = \u001b[96mself\u001b[0m._dataset_fetcher.fetch(index)  \u001b[2m# may raise StopIteration\u001b[0m              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 571 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._pin_memory:                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 572 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = _utils.pin_memory.pin_memory(data)                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m 573 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/\u001b[0m\u001b[1;33mfetch.py\u001b[0m:\u001b[94m49\u001b[0m in \u001b[92mfetch\u001b[0m              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfetch\u001b[0m(\u001b[96mself\u001b[0m, possibly_batched_index):                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.auto_collation:                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m49 \u001b[2m│   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/\u001b[0m\u001b[1;33mfetch.py\u001b[0m:\u001b[94m49\u001b[0m in \u001b[92m<listcomp>\u001b[0m         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfetch\u001b[0m(\u001b[96mself\u001b[0m, possibly_batched_index):                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.auto_collation:                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m49 \u001b[2m│   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_289/\u001b[0m\u001b[1;33m3213665558.py\u001b[0m:\u001b[94m19\u001b[0m in \u001b[92m__getitem__\u001b[0m                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_289/3213665558.py'\u001b[0m                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/\u001b[0m\u001b[1;33mimage_processing_utils.py\u001b[0m:\u001b[94m494\u001b[0m in \u001b[92m__call__\u001b[0m    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m491 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m492 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, images, **kwargs) -> BatchFeature:                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m493 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[0m                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m494 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.preprocess(images, **kwargs)                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m495 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m496 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mpreprocess\u001b[0m(\u001b[96mself\u001b[0m, images, **kwargs) -> BatchFeature:                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m497 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mEach image processor must implement its own preproces\u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/models/vit/\u001b[0m\u001b[1;33mimage_processing_vit.py\u001b[0m:\u001b[94m262\u001b[0m in    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mpreprocess\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m259 \u001b[0m\u001b[2m│   │   \u001b[0mimages = [to_numpy_array(image) \u001b[94mfor\u001b[0m image \u001b[95min\u001b[0m images]                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m do_resize:                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m262 \u001b[2m│   │   │   \u001b[0mimages = [\u001b[96mself\u001b[0m.resize(image=image, size=size_dict, resample=resample) \u001b[94mfor\u001b[0m im   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m263 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m do_rescale:                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   │   \u001b[0mimages = [\u001b[96mself\u001b[0m.rescale(image=image, scale=rescale_factor) \u001b[94mfor\u001b[0m image \u001b[95min\u001b[0m image   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/models/vit/\u001b[0m\u001b[1;33mimage_processing_vit.py\u001b[0m:\u001b[94m262\u001b[0m in    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92m<listcomp>\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m259 \u001b[0m\u001b[2m│   │   \u001b[0mimages = [to_numpy_array(image) \u001b[94mfor\u001b[0m image \u001b[95min\u001b[0m images]                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m260 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m do_resize:                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m262 \u001b[2m│   │   │   \u001b[0mimages = [\u001b[96mself\u001b[0m.resize(image=image, size=size_dict, resample=resample) \u001b[94mfor\u001b[0m im   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m263 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m264 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m do_rescale:                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   │   │   \u001b[0mimages = [\u001b[96mself\u001b[0m.rescale(image=image, scale=rescale_factor) \u001b[94mfor\u001b[0m image \u001b[95min\u001b[0m image   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/models/vit/\u001b[0m\u001b[1;33mimage_processing_vit.py\u001b[0m:\u001b[94m127\u001b[0m in    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mresize\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mheight\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m size \u001b[95mor\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mwidth\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m size:                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mThe `size` dictionary must contain the keys `height` and \u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m resize(                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m127 \u001b[2m│   │   │   \u001b[0mimage, size=(size[\u001b[33m\"\u001b[0m\u001b[33mheight\u001b[0m\u001b[33m\"\u001b[0m], size[\u001b[33m\"\u001b[0m\u001b[33mwidth\u001b[0m\u001b[33m\"\u001b[0m]), resample=resample, data_format=   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m130 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mrescale\u001b[0m(                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/\u001b[0m\u001b[1;33mimage_transforms.py\u001b[0m:\u001b[94m306\u001b[0m in \u001b[92mresize\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m303 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# the pillow library to resize the image and then convert back to numpy\u001b[0m                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m304 \u001b[0m\u001b[2m│   \u001b[0mdo_rescale = \u001b[94mFalse\u001b[0m                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m305 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(image, PIL.Image.Image):                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m306 \u001b[2m│   │   \u001b[0mdo_rescale = _rescale_for_pil_conversion(image)                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m307 \u001b[0m\u001b[2m│   │   \u001b[0mimage = to_pil_image(image, do_rescale=do_rescale)                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m308 \u001b[0m\u001b[2m│   \u001b[0mheight, width = size                                                                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m309 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# PIL images are in the format (width, height)\u001b[0m                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.7/site-packages/transformers/\u001b[0m\u001b[1;33mimage_transforms.py\u001b[0m:\u001b[94m142\u001b[0m in                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92m_rescale_for_pil_conversion\u001b[0m                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   │   \u001b[0mdo_rescale = \u001b[94mTrue\u001b[0m                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m142 \u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mThe image to be converted to a PIL image contains values outside the range \u001b[0m   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mgot [\u001b[0m\u001b[33m{\u001b[0mimage.min()\u001b[33m}\u001b[0m\u001b[33m, \u001b[0m\u001b[33m{\u001b[0mimage.max()\u001b[33m}\u001b[0m\u001b[33m] which cannot be converted to uint8.\u001b[0m\u001b[33m\"\u001b[0m      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m145 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m do_rescale                                                                      \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mValueError: \u001b[0mThe image to be converted to a PIL image contains values outside the range \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m, got \u001b[1m[\u001b[0m\u001b[1;36m-1.0\u001b[0m, \u001b[1;36m1.0\u001b[0m\u001b[1m]\u001b[0m \nwhich cannot be converted to uint8.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_289/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2896216190.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">11</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_289/2896216190.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1543</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1540 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1541 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1542 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1543 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>ignore_keys_for_eval=ignore_keys_for_eval,                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1544 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1545 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1546 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1779</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1776 │   │   │   │   </span>rng_to_sync = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1777 │   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1778 │   │   │   </span>step = -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1779 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> step, inputs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(epoch_iterator):                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1780 │   │   │   │   </span>total_batched_samples += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1781 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> rng_to_sync:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1782 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._load_rng_state(resume_from_checkpoint)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data_loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">377</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">374 │   │   </span>dataloader_iter = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>()                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">375 │   │   # We iterate one batch ahead to check when we are at the end</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">376 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>377 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>current_batch = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">next</span>(dataloader_iter)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">378 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">StopIteration</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">379 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">yield</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">380 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">530</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 527 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.autograd.profiler.record_function(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._profile_name):                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 530 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 531 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 532 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">570</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 567 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 568 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 569 │   │   </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_index()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 570 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_fetcher.fetch(index)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 571 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 572 │   │   │   </span>data = _utils.pin_memory.pin_memory(data)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 573 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">49</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, possibly_batched_index):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.auto_collation:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>49 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">49</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, possibly_batched_index):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.auto_collation:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>49 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">52 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_289/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3213665558.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_289/3213665558.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">image_processing_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">494</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">491 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">492 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, images, **kwargs) -&gt; BatchFeature:                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">493 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Preprocess an image or a batch of images.\"\"\"</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>494 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.preprocess(images, **kwargs)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">495 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">496 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">preprocess</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, images, **kwargs) -&gt; BatchFeature:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">497 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Each image processor must implement its own preproces</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">image_processing_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">262</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">preprocess</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">259 │   │   </span>images = [to_numpy_array(image) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> image <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> images]                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> do_resize:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>262 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>images = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.resize(image=image, size=size_dict, resample=resample) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> im   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">263 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> do_rescale:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   │   </span>images = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.rescale(image=image, scale=rescale_factor) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> image <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> image   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">image_processing_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">262</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">259 │   │   </span>images = [to_numpy_array(image) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> image <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> images]                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">260 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> do_resize:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>262 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>images = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.resize(image=image, size=size_dict, resample=resample) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> im   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">263 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">264 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> do_rescale:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   │   │   </span>images = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.rescale(image=image, scale=rescale_factor) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> image <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> image   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/models/vit/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">image_processing_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">127</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">resize</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"height\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> size <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"width\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> size:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"The `size` dictionary must contain the keys `height` and </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> resize(                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>127 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>image, size=(size[<span style=\"color: #808000; text-decoration-color: #808000\">\"height\"</span>], size[<span style=\"color: #808000; text-decoration-color: #808000\">\"width\"</span>]), resample=resample, data_format=   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">130 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">rescale</span>(                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">image_transforms.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">306</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">resize</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">303 │   # the pillow library to resize the image and then convert back to numpy</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">304 │   </span>do_rescale = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">305 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(image, PIL.Image.Image):                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>306 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>do_rescale = _rescale_for_pil_conversion(image)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307 │   │   </span>image = to_pil_image(image, do_rescale=do_rescale)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">308 │   </span>height, width = size                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">309 │   # PIL images are in the format (width, height)</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.7/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">image_transforms.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">142</span> in                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_rescale_for_pil_conversion</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   │   </span>do_rescale = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>142 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"The image to be converted to a PIL image contains values outside the range </span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">143 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"got [{</span>image.min()<span style=\"color: #808000; text-decoration-color: #808000\">}, {</span>image.max()<span style=\"color: #808000; text-decoration-color: #808000\">}] which cannot be converted to uint8.\"</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">144 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">145 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> do_rescale                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>The image to be converted to a PIL image contains values outside the range <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">]</span>, got <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">]</span> \nwhich cannot be converted to uint8.\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('VIT_large_gpt2')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:07.757033Z","iopub.status.idle":"2023-06-22T17:14:07.757659Z","shell.execute_reply.started":"2023-06-22T17:14:07.757304Z","shell.execute_reply":"2023-06-22T17:14:07.757332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img =  Image.open(\"/kaggle/input/flickr8k/Images/1001773457_577c3a7d70.jpg\").convert(\"RGB\")\nimg","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:07.758757Z","iopub.status.idle":"2023-06-22T17:14:07.759204Z","shell.execute_reply.started":"2023-06-22T17:14:07.758976Z","shell.execute_reply":"2023-06-22T17:14:07.758998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_caption = tokenizer.decode(model.generate(feature_extractor(img, return_tensors=\"pt\").pixel_values.to(\"cuda\"))[0])\nprint('\\033[96m' +generated_caption[:85]+ '\\033[0m')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:07.761553Z","iopub.status.idle":"2023-06-22T17:14:07.762374Z","shell.execute_reply.started":"2023-06-22T17:14:07.762067Z","shell.execute_reply":"2023-06-22T17:14:07.762092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img =  Image.open(\"/kaggle/input/flickr8k/Images/1000268201_693b08cb0e.jpg\").convert(\"RGB\")\nimg","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:07.763783Z","iopub.status.idle":"2023-06-22T17:14:07.764548Z","shell.execute_reply.started":"2023-06-22T17:14:07.764254Z","shell.execute_reply":"2023-06-22T17:14:07.764280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_caption = tokenizer.decode(model.generate(feature_extractor(img, return_tensors=\"pt\").pixel_values.to(\"cuda\"))[0])\nprint('\\033[96m' +generated_caption[:120]+ '\\033[0m')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-06-22T17:14:07.766000Z","iopub.status.idle":"2023-06-22T17:14:07.766765Z","shell.execute_reply.started":"2023-06-22T17:14:07.766483Z","shell.execute_reply":"2023-06-22T17:14:07.766508Z"},"trusted":true},"execution_count":null,"outputs":[]}]}